{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0892dcde",
   "metadata": {},
   "source": [
    "# Language Identification Hackathon\n",
    "\n",
    "©  Explore Data Science Academy\n",
    "\n",
    "---\n",
    "\n",
    "### Honour Code\n",
    "\n",
    "I **MARVIC** **COCOUVI**, confirm - by submitting this document - that the solutions in this notebook are a result of our own work and that we abide by the [EDSA honour code](https://drive.google.com/file/d/1QDCjGZJ8-FmJE3bZdIQNwnJyQKPhHZBn/view?usp=sharing).\n",
    "\n",
    "Non-compliance with the honour code constitutes a material breach of contract.\n",
    "\n",
    "<img src=\"climate_change.jpg\" width=\"800px\">\n",
    "    <figcaption><p text_align = \"center\">\n",
    "    \n",
    "    \n",
    "## **Language identification**\n",
    "\n",
    "Overview\n",
    "South Africa is a multicultural society that is characterised by its rich linguistic diversity. Language is an indispensable tool that can be used to deepen democracy and also contribute to the social, cultural, intellectual, economic and political life of the South African society.\n",
    "\n",
    "The country is multilingual with 11 official languages, each of which is guaranteed equal status. Most South Africans are multilingual and able to speak at least two or more of the official languages.\n",
    "From South African Government"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9ffdef",
   "metadata": {},
   "source": [
    "<a id=\"cont\"></a>\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "<a href=#one>1. Importing Packages</a>\n",
    "\n",
    "<a href=#two>2. Loading Data</a>\n",
    "\n",
    "<a href=#three>3. Exploratory Data Analysis (EDA)</a>\n",
    "\n",
    "<a href=#four>4. Modeling</a>\n",
    "\n",
    "<a href=#five>5. Submission</a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f6e442",
   "metadata": {},
   "source": [
    "<a id=\"one\"></a>\n",
    "## 1. Importing Packages\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Importing Packages ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section the required packages are imported, and briefly discuss, the libraries that will be used throughout the analysis and modelling. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05651a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\cocou\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\cocou\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Libraries for data loading, data manipulation and data visulisation\n",
    "import numpy as np # for linear algebra\n",
    "import pandas as pd # for importing, creating and manipulating dataframes\n",
    "\n",
    "#Visualization Packages\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Packages for text manipulation and Natural language processing\n",
    "import re\n",
    "from string import punctuation\n",
    "import nltk\n",
    "nltk.download(['stopwords','punkt'])\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "# Train-test split package\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# Libraries for data preparation and model building\n",
    "##Accuracy packages\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn import metrics\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af804878",
   "metadata": {},
   "source": [
    "<a id=\"two\"></a>\n",
    "## 2. Loading Data\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Loading the data ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section you are required to load the data from the `df_train` file into a DataFrame. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6648971",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('C:/Users/cocou/OneDrive/Desktop/Books/test_set.csv')\n",
    "train_df = pd.read_csv('C:/Users/cocou/OneDrive/Desktop/Books/train_set.csv')\n",
    "sample_submission_df = pd.read_csv('C:/Users/cocou/OneDrive/Desktop/Books/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "330e8b33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xho</td>\n",
       "      <td>umgaqo-siseko wenza amalungiselelo kumaziko ax...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xho</td>\n",
       "      <td>i-dha iya kuba nobulumko bokubeka umsebenzi na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eng</td>\n",
       "      <td>the province of kwazulu-natal department of tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nso</td>\n",
       "      <td>o netefatša gore o ba file dilo ka moka tše le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ven</td>\n",
       "      <td>khomishini ya ndinganyiso ya mbeu yo ewa maana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nso</td>\n",
       "      <td>dinyakišišo tše tša go dirwa gabedi ka ngwaga ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tsn</td>\n",
       "      <td>kgetse nngwe le nngwe e e sa faposiwang mo tsh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ven</td>\n",
       "      <td>mbadelo dze dza laelwa dzi do kwama mahatulele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>nso</td>\n",
       "      <td>maloko a dikhuduthamaga a ikarabela mongwe le ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tsn</td>\n",
       "      <td>fa le dirisiwa lebone le tshwanetse go bontsha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lang_id                                               text\n",
       "0     xho  umgaqo-siseko wenza amalungiselelo kumaziko ax...\n",
       "1     xho  i-dha iya kuba nobulumko bokubeka umsebenzi na...\n",
       "2     eng  the province of kwazulu-natal department of tr...\n",
       "3     nso  o netefatša gore o ba file dilo ka moka tše le...\n",
       "4     ven  khomishini ya ndinganyiso ya mbeu yo ewa maana...\n",
       "5     nso  dinyakišišo tše tša go dirwa gabedi ka ngwaga ...\n",
       "6     tsn  kgetse nngwe le nngwe e e sa faposiwang mo tsh...\n",
       "7     ven  mbadelo dze dza laelwa dzi do kwama mahatulele...\n",
       "8     nso  maloko a dikhuduthamaga a ikarabela mongwe le ...\n",
       "9     tsn  fa le dirisiwa lebone le tshwanetse go bontsha..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a6821c0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Mmasepala, fa maemo a a kgethegileng a letlele...</td>\n",
       "      <td>mmasepala, fa maemo a a kgethegileng a letlele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Uzakwaziswa ngokufaneleko nakungafuneka eminye...</td>\n",
       "      <td>uzakwaziswa ngokufaneleko nakungafuneka eminye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Tshivhumbeo tshi fana na ngano dza vhathu.</td>\n",
       "      <td>tshivhumbeo tshi fana na ngano dza vhathu.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Kube inja nelikati betingevakala kutsi titsini...</td>\n",
       "      <td>kube inja nelikati betingevakala kutsi titsini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Winste op buitelandse valuta.</td>\n",
       "      <td>winste op buitelandse valuta.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                               text  \\\n",
       "0      1  Mmasepala, fa maemo a a kgethegileng a letlele...   \n",
       "1      2  Uzakwaziswa ngokufaneleko nakungafuneka eminye...   \n",
       "2      3         Tshivhumbeo tshi fana na ngano dza vhathu.   \n",
       "3      4  Kube inja nelikati betingevakala kutsi titsini...   \n",
       "4      5                      Winste op buitelandse valuta.   \n",
       "\n",
       "                                      processed_text  \n",
       "0  mmasepala, fa maemo a a kgethegileng a letlele...  \n",
       "1  uzakwaziswa ngokufaneleko nakungafuneka eminye...  \n",
       "2         tshivhumbeo tshi fana na ngano dza vhathu.  \n",
       "3  kube inja nelikati betingevakala kutsi titsini...  \n",
       "4                      winste op buitelandse valuta.  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba563214",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b448b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc076e92",
   "metadata": {},
   "source": [
    "## 3. ALL EDA / DATA PRE-PROCESSING HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b67c4fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ba413a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['lang_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b480ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing(text):\n",
    "    \n",
    "    '''\n",
    "    This functions cleans tweets from line breaks, URLs, numbers, etc.\n",
    "    '''\n",
    "    \n",
    "    text = text.lower() #to lower case\n",
    "    text = text.replace('\\n', ' ') # remove line breaks\n",
    "    text = text.replace('\\@(\\w*)', '') # remove mentions\n",
    "    text = re.sub(r\"\\bhttps://t.co/\\w+\", '', text) # remove URLs\n",
    "    text = re.sub('\\w*\\d\\w*', '', text) # remove numbers\n",
    "    text = re.sub(r'\\#', '', text) # remove hashtags. To remove full hashtag: '\\#(\\w*)'\n",
    "    text = re.sub('\\w*\\d\\w*', '', text) # removes numbers?\n",
    "    text = re.sub(' +', ' ', text) # remove 1+ spaces\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6403822b",
   "metadata": {},
   "source": [
    "# 4. Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c915e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the labels and features\n",
    "train_df['processed_text'] = train_df['text'].apply(text_preprocessing)\n",
    "X = train_df['text'].values\n",
    "y = train_df['lang_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f1756d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['processed_text'] = test_df['text'].apply(text_preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37dc9d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the labels and fetures into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10,random_state=42,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8482b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb = Pipeline([('Count',CountVectorizer()),('classify',MultinomialNB())])\n",
    "#fitting the model\n",
    "mnb.fit(X_train, y_train)\n",
    "\n",
    "#apply model on test data\n",
    "y_pred_mnb = mnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad405bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         afr       1.00      1.00      1.00       300\n",
      "         eng       0.99      1.00      1.00       300\n",
      "         nbl       1.00      1.00      1.00       300\n",
      "         nso       1.00      1.00      1.00       300\n",
      "         sot       1.00      1.00      1.00       300\n",
      "         ssw       1.00      1.00      1.00       300\n",
      "         tsn       1.00      1.00      1.00       300\n",
      "         tso       1.00      1.00      1.00       300\n",
      "         ven       1.00      1.00      1.00       300\n",
      "         xho       1.00      0.99      1.00       300\n",
      "         zul       1.00      1.00      1.00       300\n",
      "\n",
      "    accuracy                           1.00      3300\n",
      "   macro avg       1.00      1.00      1.00      3300\n",
      "weighted avg       1.00      1.00      1.00      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "print(classification_report(y_test, y_pred_mnb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2afed1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVC\n",
    "svc = Pipeline([('Count',CountVectorizer()),('classify',SVC(max_iter=300,C=1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5cedf902",
   "metadata": {},
   "outputs": [],
   "source": [
    "#linearSVC\n",
    "linsvc = Pipeline([('Count',CountVectorizer()),('classify',LinearSVC(max_iter=300,C=1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "abc15024",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression\n",
    "lr = Pipeline([('Count',CountVectorizer()),('classify',LogisticRegression(max_iter=300))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8253d2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoke the KNN classifier\n",
    "knn = Pipeline([('Count',CountVectorizer()),('classify',KNeighborsClassifier(n_neighbors=3))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c034f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call up the Random Forest Sampler\n",
    "rf = Pipeline([('Count',CountVectorizer()),('classify',RandomForestClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f9bab0f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average weighted F1 score over 3 SVC models is 0.9845704691936438\n"
     ]
    }
   ],
   "source": [
    "num=3\n",
    "# SVC\n",
    "scores = cross_val_score(\n",
    "        svc, X, y, cv=num, scoring='f1_weighted')\n",
    "print('The average weighted F1 score over '+str(num)+' SVC models is ' + str(sum(scores)/len(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f026653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average weighted F1 score over 3 LinearSVC models is 0.9965452288607383\n"
     ]
    }
   ],
   "source": [
    "#linearSVC\n",
    "scores = cross_val_score(\n",
    "        linsvc, X, y, cv=num, scoring='f1_weighted')\n",
    "print('The average weighted F1 score over '+str(num)+ ' LinearSVC models is ' + str(sum(scores)/len(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d0bd644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average weighted F1 score over 3 Logistic Regression models is 0.9951497185965673\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "scores = cross_val_score(\n",
    "        lr, X, y, cv=num, scoring='f1_weighted')\n",
    "print('The average weighted F1 score over '+str(num)+' Logistic Regression models is ' + str(sum(scores)/len(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "69635f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average weighted F1 score over 3 KNN models is 0.9012927517522525\n"
     ]
    }
   ],
   "source": [
    "#KNN\n",
    "scores = cross_val_score(\n",
    "        knn, X, y, cv=num, scoring='f1_weighted')\n",
    "print('The average weighted F1 score over '+str(num)+' KNN models is ' + str(sum(scores)/len(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ffaeadfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average weighted F1 score over 3 KNN models is 0.9868922435102471\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "scores = cross_val_score(\n",
    "        rf, X, y, cv=num, scoring='f1_weighted')\n",
    "print('The average weighted F1 score over '+str(num)+' KNN models is ' + str(sum(scores)/len(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea675791",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree\n",
    "dt = Pipeline([('Count',CountVectorizer()),('classify',DecisionTreeClassifier())])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e70317e",
   "metadata": {},
   "source": [
    "**Hyperparameter Tuning** \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b777b880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "Cs = [0.001, 0.01, 0.1, 1, 10]\n",
    "param_grid = {\n",
    "    'C'     : Cs\n",
    "    }\n",
    "grid_SVM = GridSearchCV(LogisticRegression(), param_grid, scoring='f1_weighted', cv=3)\n",
    "grid_SVM.fit(CountVectorizer().fit_transform(X), y)\n",
    "grid_SVM.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "61a43eb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'C'     : Cs }\n",
    "grid_SVM = GridSearchCV(LinearSVC(), param_grid, scoring='f1_weighted', cv=3)\n",
    "grid_SVM.fit(CountVectorizer().fit_transform(X), y)\n",
    "grid_SVM.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9e9d2a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [\n",
    "        ('rf', Pipeline([('Count',CountVectorizer(ngram_range=(1,2))),('classify',RandomForestClassifier())])),\n",
    "         \n",
    "        ('lnsvc', Pipeline([('Count',CountVectorizer(ngram_range=(1,2))),('classify',LinearSVC(C=0.1))])),\n",
    "         \n",
    "        ('MNB',Pipeline([('Count',CountVectorizer()),('classify',MultinomialNB())])),\n",
    "    \n",
    "        ('lr', Pipeline([('Count',CountVectorizer(ngram_range=(1,2))),('classify',LogisticRegression(C=1))]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6b8985a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StackingClassifier(estimators=[(&#x27;rf&#x27;,\n",
       "                                Pipeline(steps=[(&#x27;Count&#x27;,\n",
       "                                                 CountVectorizer(ngram_range=(1,\n",
       "                                                                              2))),\n",
       "                                                (&#x27;classify&#x27;,\n",
       "                                                 RandomForestClassifier())])),\n",
       "                               (&#x27;lnsvc&#x27;,\n",
       "                                Pipeline(steps=[(&#x27;Count&#x27;,\n",
       "                                                 CountVectorizer(ngram_range=(1,\n",
       "                                                                              2))),\n",
       "                                                (&#x27;classify&#x27;,\n",
       "                                                 LinearSVC(C=0.1))])),\n",
       "                               (&#x27;MNB&#x27;,\n",
       "                                Pipeline(steps=[(&#x27;Count&#x27;, CountVectorizer()),\n",
       "                                                (&#x27;classify&#x27;,\n",
       "                                                 MultinomialNB())])),\n",
       "                               (&#x27;lr&#x27;,\n",
       "                                Pipeline(steps=[(&#x27;Count&#x27;,\n",
       "                                                 CountVectorizer(ngram_range=(1,\n",
       "                                                                              2))),\n",
       "                                                (&#x27;classify&#x27;,\n",
       "                                                 LogisticRegression(C=1))])),\n",
       "                               (&#x27;knn&#x27;,\n",
       "                                Pipeline(steps=[(&#x27;Count&#x27;, CountVectorizer()),\n",
       "                                                (&#x27;classify&#x27;,\n",
       "                                                 KNeighborsClassifier(n_neighbors=3))]))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StackingClassifier</label><div class=\"sk-toggleable__content\"><pre>StackingClassifier(estimators=[(&#x27;rf&#x27;,\n",
       "                                Pipeline(steps=[(&#x27;Count&#x27;,\n",
       "                                                 CountVectorizer(ngram_range=(1,\n",
       "                                                                              2))),\n",
       "                                                (&#x27;classify&#x27;,\n",
       "                                                 RandomForestClassifier())])),\n",
       "                               (&#x27;lnsvc&#x27;,\n",
       "                                Pipeline(steps=[(&#x27;Count&#x27;,\n",
       "                                                 CountVectorizer(ngram_range=(1,\n",
       "                                                                              2))),\n",
       "                                                (&#x27;classify&#x27;,\n",
       "                                                 LinearSVC(C=0.1))])),\n",
       "                               (&#x27;MNB&#x27;,\n",
       "                                Pipeline(steps=[(&#x27;Count&#x27;, CountVectorizer()),\n",
       "                                                (&#x27;classify&#x27;,\n",
       "                                                 MultinomialNB())])),\n",
       "                               (&#x27;lr&#x27;,\n",
       "                                Pipeline(steps=[(&#x27;Count&#x27;,\n",
       "                                                 CountVectorizer(ngram_range=(1,\n",
       "                                                                              2))),\n",
       "                                                (&#x27;classify&#x27;,\n",
       "                                                 LogisticRegression(C=1))])),\n",
       "                               (&#x27;knn&#x27;,\n",
       "                                Pipeline(steps=[(&#x27;Count&#x27;, CountVectorizer()),\n",
       "                                                (&#x27;classify&#x27;,\n",
       "                                                 KNeighborsClassifier(n_neighbors=3))]))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>rf</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(ngram_range=(1, 2))</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lnsvc</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(ngram_range=(1, 2))</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" ><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC(C=0.1)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>MNB</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-27\" type=\"checkbox\" ><label for=\"sk-estimator-id-27\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" ><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lr</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-29\" type=\"checkbox\" ><label for=\"sk-estimator-id-29\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(ngram_range=(1, 2))</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-30\" type=\"checkbox\" ><label for=\"sk-estimator-id-30\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=1)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>knn</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-31\" type=\"checkbox\" ><label for=\"sk-estimator-id-31\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-32\" type=\"checkbox\" ><label for=\"sk-estimator-id-32\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=3)</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-33\" type=\"checkbox\" ><label for=\"sk-estimator-id-33\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "StackingClassifier(estimators=[('rf',\n",
       "                                Pipeline(steps=[('Count',\n",
       "                                                 CountVectorizer(ngram_range=(1,\n",
       "                                                                              2))),\n",
       "                                                ('classify',\n",
       "                                                 RandomForestClassifier())])),\n",
       "                               ('lnsvc',\n",
       "                                Pipeline(steps=[('Count',\n",
       "                                                 CountVectorizer(ngram_range=(1,\n",
       "                                                                              2))),\n",
       "                                                ('classify',\n",
       "                                                 LinearSVC(C=0.1))])),\n",
       "                               ('MNB',\n",
       "                                Pipeline(steps=[('Count', CountVectorizer()),\n",
       "                                                ('classify',\n",
       "                                                 MultinomialNB())])),\n",
       "                               ('lr',\n",
       "                                Pipeline(steps=[('Count',\n",
       "                                                 CountVectorizer(ngram_range=(1,\n",
       "                                                                              2))),\n",
       "                                                ('classify',\n",
       "                                                 LogisticRegression(C=1))])),\n",
       "                               ('knn',\n",
       "                                Pipeline(steps=[('Count', CountVectorizer()),\n",
       "                                                ('classify',\n",
       "                                                 KNeighborsClassifier(n_neighbors=3))]))])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = StackingClassifier(\n",
    "        estimators=estimators, final_estimator=LogisticRegression()\n",
    "    )\n",
    "\n",
    "#fitting the model\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8054d06f",
   "metadata": {},
   "source": [
    "<a id=\"save\"></a>\n",
    "## 5. SUBMISSION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9800389a",
   "metadata": {},
   "source": [
    "Let's create the csv file that will help us to make submission on Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d1f17977",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_unseen = test_df['processed_text']\n",
    "\n",
    "submission = pd.DataFrame(\n",
    "    {'index': test_df['index'],\n",
    "     'lang_id': clf.predict(x_unseen)\n",
    "    })\n",
    "\n",
    "# save DataFrame to csv file for submission\n",
    "submission.to_csv(\"Submission_final.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f91012",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
